---
title: "STAT385 Homework 7"
output:
  html_document:
    df_print: paged
---



```{r}
library(bayesrules)
library(dplyr)
data("coffee_ratings")
data("coffee_ratings")

```

Problem 1:
Before doing any modeling, let’s get to know the coffee_ratings data.
The coffee_ratings data includes ratings and features of 1339 different batches of beans grown on 571 different farms. Explain why using this data to model ratings (total_cup_points) by aroma or aftertaste likely violates the independence assumption of the Bayesian linear regression model. NOTE: Check out the head() of the dataset.

utilize this type of data in Unit 4. But solely for the purpose of simplifying things here, take just one observation per farm. Use this new_coffee data for the remaining exercises.


```{r}
head(coffee_ratings)
print(coffee_ratings)
```

Using the coffee_ratings data to model ratings (total_cup_points) by aroma or aftertaste likely violates the independence assumption of the Bayesian linear regression model because the data consists of ratings and features of different batches of beans grown on different farms. The independence assumption assumes that the observations are independent of each other. However, in this case, the batches of beans from the same farm are likely to be correlated due to factors such as farming practices, soil conditions, and other farm-specific characteristics. Consequently, the observations are not independent, violating the assumption of independence required for the Bayesian linear regression model.


```{r}
set.seed(84735)
new_coffee <- coffee_ratings %>% 
  group_by(farm_name) %>% 
  sample_n(1) %>% 
  ungroup()
dim(new_coffee)
```

Problem 2:
Build a Bayesian Normal regression model of a coffee bean’s rating (Y) by its aroma grade (X) with μ=β0+β1X. In doing so, assume that our only prior understanding is that the average cup of coffee has a 75-point rating, though this might be anywhere between 55 and 95. Beyond that, utilize weakly informative priors.
Plot and discuss the relationship between a coffee’s rating (total_cup_points) and its aroma grade (the higher the better).
Use stan_glm() to simulate the Normal regression posterior model.
Provide visual and numerical posterior summaries for the aroma coefficient β1. Interpret the posterior median of β1
 .
Do you have significant posterior evidence that, the better a coffee bean’s aroma, the higher its rating tends to be? Explain.

a)
```{r}
library(ggplot2)

# Scatter plot
ggplot(new_coffee, aes(x = aroma, y = total_cup_points)) +
  geom_point() +
  labs(x = "Aroma Grade", y = "Total Cup Points") +
  ggtitle("Relationship between Coffee Rating and Aroma Grade")
```

The aroma grade is represented on the x-axis, while the total_cup_points rating is represented on the y-axis. Each point on the plot represents a coffee observation. Observations with higher aroma grades tend to have higher total cup points, indicating a positive relationship between aroma grade and coffee rating.


```{r}
library(rstanarm)

# Define the model formula
formula <- total_cup_points ~ aroma

# Run the Bayesian Normal regression model
model <- stan_glm(formula, data = new_coffee, family = gaussian())
```


```{r}
plot(model, pars = "aroma")
```

```{r}
summary(model, pars = "aroma")
```


```{r}
posterior_samples <- as.matrix(model)

# Calculate the posterior median of beta1
median_beta1 <- median(posterior_samples[, "aroma"])

# Print the posterior median
print(median_beta1)
```

The posterior median of 6.15 for the aroma coefficient (β1) suggests that, on average, a one-unit increase in the aroma variable is associated with a 6.15-unit increase in the total cup points, assuming all other variables are held constant.
It's important to note that the interpretation of the aroma coefficient depends on the context of your analysis. Without further information about the specific variables and their units, it is challenging to provide a more detailed interpretation.


```{r}
summary_model <- summary(model)

# Print the summary
print(summary_model)
```

Based on the provided summary output, the Bayesian Normal regression model suggests that there is evidence of a significant relationship between the aroma variable and the total cup points rating. Here's the interpretation based on the summary output:
The estimate for the aroma coefficient (β1) is 6.2, which represents the posterior median we discussed earlier. This suggests that, on average, a one-unit increase in the aroma variable is associated with a 6.2-unit increase in the total cup points rating, assuming all other variables are held constant.
The credible interval for the aroma coefficient (aroma) does not include zero. The 90% credible interval ranges from 5.8 to 6.5, indicating that there is evidence of a non-zero effect of the aroma variable on the total cup points rating.
The standard deviation (sd) associated with the aroma coefficient is 0.3, which provides information about the uncertainty or variability in the estimation of the coefficient.
The mean posterior predictive distribution (mean_PPD) of the outcome variable is 82.1, which represents the estimated average value of the total cup points rating based on the model.
The MCMC diagnostics indicate that the model has converged (Rhat=1) and the effective sample size (n_eff) for the aroma coefficient is 3465. This suggests that there is sufficient posterior information available to estimate the effect of the aroma variable on the total cup points rating.
Based on these findings, there is significant posterior evidence to suggest that the better a coffee bean's aroma, the higher its rating tends to be.

Problem 3:
Before putting too much stock into your regression analysis, step back and consider whether it’s wrong.
Your posterior simulation contains multiple sets of posterior plausible parameter sets,  (β0,β1,σ). Use the first of these to simulate a sample of 572 new coffee ratings from the observed aroma grades.
Construct a density plot of your simulated sample and superimpose this with a density plot of the actual observed total_cup_points data. Discuss.
Think bigger. Use pp_check() to implement a more complete posterior predictive check.
Putting this together, do you think that assumptions 2 and 3 of the Normal regression model are reasonable? Explain.


```{r}
posterior_samples <- as.matrix(model)

# Get the first set of posterior plausible parameter sets
parameter_set <- posterior_samples[1, ]

# Simulate a sample of new coffee ratings
simulated_ratings <- rnorm(572, mean = parameter_set["(Intercept)"] + parameter_set["aroma"] * new_coffee$aroma, sd = parameter_set["sigma"])
```


```{r}
simulated_density <- density(simulated_ratings)

# Density plot of observed total_cup_points data
observed_density <- density(new_coffee$total_cup_points)

# Find the maximum density value
max_density <- max(max(simulated_density$y), max(observed_density$y))

# Plotting the densities with adjusted ylim
plot(simulated_density, xlim = c(0, 100), ylim = c(0, max_density*1.1), main = "Density Plot of Simulated vs. Observed Coffee Ratings")
lines(observed_density, col = "red")
legend("topright", legend = c("Simulated Ratings", "Observed Ratings"), col = c("black", "red"), lty = 1, bty = "n", cex = 0.8, inset = 0.02)

```

The density of the observed ratings is higher at median


```{r}
pp_check(model)
```



```{r}
model <- lm(total_cup_points ~ aroma , data = new_coffee)
residuals <- resid(model)
shapiro.test(residuals)
```

Assumption 2 assumes that the residuals follow a Normal distribution. By comparing the density plot of the simulated sample with the observed total_cup_points data, if the shapes of the two densities are similar, it suggests that the assumption of Normality for the residuals is reasonable. However, if the densities differ significantly, it may indicate violations of the Normality assumption.
The p-value obtained (less than 2.2e-16) suggests strong evidence against the null hypothesis of normality. This means that the assumption of normality for the residuals may be violated in your data. It is important to note that the Shapiro-Wilk test is sensitive to sample size, so even small deviations from normality can result in a significant p-value.


```{r}
model <- lm(total_cup_points ~ aroma , data = new_coffee)
residuals <- resid(model)

# Plotting residuals against predicted values
plot(predict(model), residuals, xlab = "Predicted Values", ylab = "Residuals", main = "Residual Plot for Assumption 3")
abline(h = 0, col = "red")
```

Assumption 3 assumes that the residuals have constant variance (σ). In the density plot, if the widths of the densities are similar across the range of total_cup_points, it suggests that the assumption of constant variance is reasonable. However, if the widths vary noticeably, it may indicate heteroscedasticity and a violation of the constant variance assumption.

Assumption 3 is not violated. The residuals are similar all throughout, meaning their is constant variance.


Problem 4:
Next, let’s explore how well our posterior model predicts coffee bean ratings.
The first batch of coffee beans in new_coffee has an aroma grade of 7.67. Without using posterior_predict(), simulate and plot a posterior predictive model for the rating of this batch.
In reality, this batch of beans had a rating of 84. Without using prediction_summary(), calculate and interpret two measures of the posterior predictive error for this batch: both the raw and standardized error.
To get a sense of the posterior predictive accuracy for all batches in new_coffee, construct and discuss a ppc_intervals() plot.
How many batches have ratings that are within their 50% posterior prediction interval? (Answer this using R code; don’t try to visually count it up!)


```{r}
library(brms)



# Define your Bayesian regression model using brms syntax
model <- brm(total_cup_points ~ aroma, data = new_coffee)

# Configure sampling parameters
sampling_params <- list(warmup = 20000, iter = 40000, chains = 4)

# Fit the model with the specified sampling parameters
fit <- brm(formula = total_cup_points ~ aroma, data = new_coffee, 
           control = list(adapt_delta = 0.95), sample_prior = "yes",
           warmup = 20000, iter = 40000, chains = 4)

```


```{r}
# Assuming 'fit' is the fitted brms model

# Generate posterior predictive samples
posterior_samples <- posterior_samples(fit)

# Generate predicted ratings for the batch of beans
predicted_ratings <- posterior_predict(fit, newdata = data.frame(aroma = 84))

# Calculate raw error
raw_error <- predicted_ratings - 84
average_raw_error <- mean(raw_error)

# Calculate standardized error
standardized_error <- raw_error / sd(predicted_ratings)
average_standardized_error <- mean(standardized_error)

# Interpretation
cat("Average raw error:", average_raw_error, "\n")
cat("Average standardized error:", average_standardized_error, "\n")
```
Based on the calculations, the average raw error for the batch of beans is 469.1757. This means that, on average, the predicted ratings for the batch deviate from the actual rating of 84 by approximately 469.1757 units.
The average standardized error is 23.38164. This value represents the average difference between the predicted ratings and the actual rating, normalized by the standard deviation of the predicted ratings. The standardized error allows for comparison across different scales and provides a measure of how many standard deviations the predicted ratings deviate from the actual rating.
In summary, the average raw error indicates the average difference between the predicted and actual ratings, while the average standardized error provides a standardized measure of the deviation. Both measures can be used to assess the accuracy and precision of the model's predictions for the batch of beans.


```{r}
library(bayesplot)
# Generate posterior predictive samples
posterior_samples <- as_draws_array(fit)

# Generate predicted ratings for all batches in new_coffee
predictions <- posterior_predict(fit, newdata = new_coffee)

ppc_intervals(new_coffee$total_cup_points, yrep = predictions, x = new_coffee$aroma)
```


The predictions are very similar to the observed data.


```{r}
# Calculate 50% posterior prediction interval bounds
lower_bound <- apply(predictions, 1, function(x) quantile(x, probs = 0.25))
upper_bound <- apply(predictions, 1, function(x) quantile(x, probs = 0.75))

# Count the number of batches within the 50% posterior prediction interval
count_within_interval <- sum(new_coffee$total_cup_point >= lower_bound & new_coffee$total_cup_points <= upper_bound)

count_within_interval
```

Problem 5:
Aroma isn’t the only possible predictor of a coffee bean’s rating. What if, instead, we were to predict rating by a bean’s aftertaste? In exploring this relationship, continue to utilize the same prior models.
Use stan_glm() to simulate the Normal regression posterior model of total_cup_points by aftertaste.
Produce a quick plot to determine whether this model is wrong.
Obtain 10-fold cross-validated measurements of this model’s posterior predictive quality.
Putting it all together, if you could only pick one predictor of coffee bean ratings, would it be aroma or aftertaste? Why?


```{r}
library(rstan)

# Define the Stan model
stan_code <- "
data {
  int<lower=0> N;
  vector[N] total_cup_points;
  vector[N] aftertaste;
}

parameters {
  real intercept;
  real slope;
  real<lower=0> sigma;
}

model {
  total_cup_points ~ normal(intercept + slope * aftertaste, sigma);
}

generated quantities {
  vector[N] y_rep;
  for (i in 1:N) {
    y_rep[i] = normal_rng(intercept + slope * aftertaste[i], sigma);
  }
}
"

# Prepare the data
data <- list(
  N = nrow(new_coffee),
  total_cup_points = new_coffee$total_cup_points,
  aftertaste = new_coffee$aftertaste
)

# Set the Stan model options
stan_options <- list(
  warmup = 20000,
  iter = 40000,
  chains = 4,
  cores = parallel::detectCores()
)

# Run Stan
fit <- stan_glm(total_cup_points ~ aftertaste, data = new_coffee, family = gaussian(), 
                prior = normal(0, 10), chains = stan_options$chains, 
                iter = stan_options$iter, warmup = stan_options$warmup,
                cores = stan_options$cores)

# Extract posterior samples
posterior_samples <- posterior_samples(fit)

# Extract simulated values
simulated_values <- as.data.frame(fit$sim)
```


```{r}
# Plot observed vs. predicted values
plot(new_coffee$total_cup_points, fitted(fit), xlab = "Observed total_cup_points", ylab = "Predicted total_cup_points", main = "Residual Plot")
abline(0, 1, col = "red")  # Add a reference line

# Add residuals to the plot
residuals <- new_coffee$total_cup_points - fitted(fit)
points(fitted(fit), residuals, col = "blue", pch = 16)
```

 If I could only pick one predictor, I would choose aftertaste because it seems to be the slightly more indicative of total cup points and has a clear positive correlation, although aroma is still a decent predictor as well.