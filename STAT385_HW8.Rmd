---
title: "STAT385 Homework 8"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

1. Produce Figure 9.5

```{r}
# Load required libraries
library(ggplot2)
library(MCMCpack)
library(rstan)
library(rstanarm)
library(dplyr)
library(bayesrules)
library(tidyverse)



# Set the seed for reproducibility
set.seed(123)

# Number of lines to generate
n_lines <- 200

# Generate values from the prior distributions
beta0_samples <- rnorm(n_lines, mean = 5000, sd = 1000)
beta1_samples <- rnorm(n_lines, mean = 100, sd = 40)

# Define the range of X values
X <- seq(45, 90, length.out = 100)

# Plot the prior model lines
plot(NULL, xlim = range(X), ylim = c(0, 20000), xlab = "temperature", ylab = "number of riders", main = "200 Prior Plausible Model Lines")

# Loop over the samples and add each line to the plot
for (i in 1:n_lines) {
  lines(X, beta0_samples[i] + beta1_samples[i] * X, col = rgb(0, 0, 1, alpha = 0.1))
}
```


2. Produce Figure 9.13

```{r}
library(bayesrules)
data("bikes")

phase_1 <- bikes[1:30, ]
phase_2 <- bikes[1:60, ]
phase_3 <- bikes
# Fit the model using only the first 30 data points
phase_1_model <- stan_glm(rides ~ temp_feel, data = phase_1, family = gaussian, 
                          prior_intercept = normal(5000, 1000), 
                          prior = normal(100, 40), 
                          prior_aux = cauchy(0,1), 
                          chains = 4, iter = 5000*2, seed = 84735)

# Generate 100 plausible models
preds <- posterior_predict(phase_1_model, newdata = phase_1, draws = 100)

# Plot the data
plot(phase_1$temp_feel, phase_1$rides, xlab = "Temp Feel", ylab = "Rides", 
     main = "Data and Plausible Models at Phase 1")

# Add lines for each plausible model
for (i in 1:100) {
  lines(phase_1$temp_feel, preds[i,], col = "lightgray", lwd = 0.5)
}

```

```{r}
library(rstanarm)
bikes %>% 
  select(date, temp_feel, rides) %>% 
  head(3)

# Load the necessary libraries
library(ggplot2)

# Create the data for phase 1, 2, and 3
# Assuming the data is stored in a variable called 'bikes'

# Phase 1 data
phase_1_data <- bikes[1:30, ]

# Phase 2 data
phase_2_data <- bikes[1:60, ]

# Phase 3 data
phase_3_data <- bikes

# Create the plots for each phase
# Assuming 'temp_feel' is the temperature variable and 'rides' is the ridership variable

# Plot for phase 1
plot_phase_1 <- ggplot(phase_1_data, aes(x = temp_feel, y = rides)) +
  geom_point() +
  labs(title = "Phase 1: Ridership vs. Temperature",
       x = "Temperature",
       y = "Ridership")

# Plot for phase 2
plot_phase_2 <- ggplot(phase_2_data, aes(x = temp_feel, y = rides)) +
  geom_point() +
  labs(title = "Phase 2: Ridership vs. Temperature",
       x = "Temperature",
       y = "Ridership")

# Plot for phase 3
plot_phase_3 <- ggplot(phase_3_data, aes(x = temp_feel, y = rides)) +
  geom_point() +
  labs(title = "Phase 3: Ridership vs. Temperature",
       x = "Temperature",
       y = "Ridership")

# Display the plots
print(plot_phase_1)
print(plot_phase_2)
print(plot_phase_3)

```

```{r}

# Load the necessary libraries
library(rstan)
library(ggplot2)

# Create the data for phase 1, 2, and 3
# Assuming the data is stored in a variable called 'bikes'

# Phase 1 data
phase_1_data <- bikes[1:30, ]

# Phase 2 data
phase_2_data <- bikes[1:60, ]

# Phase 3 data
phase_3_data <- bikes

# Re-simulate the posterior model for each phase
# Assuming 'rides' is the dependent variable and 'temp_feel' is the independent variable

# Posterior model for phase 1
model_phase_1 <- stan_glm(rides ~ temp_feel, data = phase_1_data, family = gaussian,
                          prior_intercept = normal(5000, 1000),
                          prior = normal(100, 40),
                          prior_aux = exponential(0.0008),
                          chains = 4, iter = 5000*2, seed = 84735)

# Posterior model for phase 2
model_phase_2 <- stan_glm(rides ~ temp_feel, data = phase_2_data, family = gaussian,
                          prior_intercept = normal(5000, 1000),
                          prior = normal(100, 40),
                          prior_aux = exponential(0.0008),
                          chains = 4, iter = 5000*2, seed = 84735)

# Posterior model for phase 3
model_phase_3 <- stan_glm(rides ~ temp_feel, data = phase_3_data, family = gaussian,
                          prior_intercept = normal(5000, 1000),
                          prior = normal(100, 40),
                          prior_aux = exponential(0.0008),
                          chains = 4, iter = 5000*2, seed = 84735)

# Visualize the evolution of the relationship between ridership and temperature
# Assuming 'temp_feel' is the temperature variable and 'rides' is the ridership variable

# Plot for phase 1
plot_phase_1 <- ggplot(phase_1_data, aes(x = temp_feel, y = rides)) +
  geom_point() +
  geom_abline(intercept = coef(model_phase_1)[1], slope = coef(model_phase_1)[2], color = "blue") +
  labs(title = "Phase 1: Ridership vs. Temperature",
       x = "Temperature",
       y = "Ridership")
```
```{r}
# Plot for phase 2
plot_phase_2 <- ggplot(phase_2_data, aes(x = temp_feel, y = rides)) +
  geom_point() +
  geom_abline(intercept = coef(model_phase_2)[1], slope = coef(model_phase_2)[2], color = "green") +
  labs(title = "Phase 2: Ridership vs. Temperature",
       x = "Temperature",
       y = "Ridership")
```
```{r}
# Plot for phase 3
plot_phase_3 <- ggplot(phase_3_data, aes(x = temp_feel, y = rides)) +
  geom_point() +
  geom_abline(intercept = coef(model_phase_3)[1], slope = coef(model_phase_3)[2], color = "red") +
  labs(title = "Phase 3: Ridership vs. Temperature",
       x = "Temperature",
       y = "Ridership")

# Display the plots
print(plot_phase_1)
print(plot_phase_2)
print(plot_phase_3)
```


3. Exercise 9.16:


a)
```{r}
# Remove NA values
penguins_bayes <- na.omit(penguins_bayes)
prior_model <- stan_glm(flipper_length_mm ~ bill_length_mm, data = penguins_bayes, 
                        family = gaussian(), 
                        prior_intercept = normal(200, 25), 
                        prior = normal(0, 10),
                        prior_aux = cauchy(0, 5),
                        prior_PD = TRUE, 
                        chains = 4, iter = 10000)
prior_summary(prior_model)
```

b)
```{r}
prior_summary(prior_model)
```
Complete structure of Normal regression model:
1.The response variable Y is continuous, indicating a Normal model structure
2. Data: the target is flipper_length_mm and the predictor is bill_length_mm used from the penguins dataset. So, lipper_length_mm = β0 + β1 * bill_length_mm.
3. The unknown parameters are β0: The intercept parameter.
β1: The coefficient for the predictor variable bill_length_mm.
4. Specify the prior models for the unknown parameters:
Prior for the intercept (β0): β0 ~ Normal(location = 201, scale = 35)
Prior for coefficients (β1, β2, ...): β1, β2, ... ~ Normal(location = 0, scale = 6.4)
Prior for the standard deviation (σ): σ ~ Exponential(rate = 0.071)
5.The likelihood of the data is assumed to follow a Normal distribution, with the mean (μ) being equal to the model equation (β0 + β1 * bill_length_mm), and the standard deviation (σ) representing the variability of the data around the mean.


c)
```{r}
prior_preds <- posterior_linpred(prior_model, draws = 100)

# Combine the predictions with the bill lengths
prior_df <- data.frame(bill_length_mm = penguins_bayes$bill_length_mm, 
                       t(prior_preds))

# Reshape to long format
prior_df_long <- gather(prior_df, model, flipper_length_mm, -bill_length_mm)

# Plot
ggplot(prior_df_long, aes(x = bill_length_mm, y = flipper_length_mm)) +
  geom_line(aes(group = model), colour = "lightgray") +
  geom_point(data = penguins_bayes, aes(x = bill_length_mm, y = flipper_length_mm)) +
  labs(x = "Bill Length (mm)", y = "Flipper Length (mm)", 
       title = "Prior Plausible Models and Observed Data") +
  theme_minimal()

```


d)
 The variability in these lines also adequately reflects our overall uncertainty about this association. 



4. Exercise 9.17

a)
```{r}
# Plot the relationship between flipper_length_mm and bill_length_mm
plot(penguins_bayes$bill_length_mm, penguins_bayes$flipper_length_mm, pch = 16, col = "black",
     xlab = "Bill Length (mm)", ylab = "Flipper Length (mm)")
```

```{r}
# Calculate the correlation coefficient, handling missing values
correlation <- cor(penguins_bayes$bill_length_mm, penguins_bayes$flipper_length_mm, use = "complete.obs")

# Print the correlation coefficient
print(correlation)
```

b)
Given that the plot shows linearity and that the correlation coefficient is relatively close to 1, a Normal regression model is a reasonable approach.

5. Exercise 9.18

a)
```{r}
 formula <- flipper_length_mm ~ bill_length_mm # Simulate the Normal regression posterior model 


# Specify the prior distributions for the intercept, coefficient, and auxiliary parameter (sigma)
prior_intercept <- normal(location = 201, scale = 35)
prior <- normal(location = 0, scale = 6.4)
prior_auxiliary <- exponential(rate = 0.071)

# Fit the posterior model with specified priors
posterior_model <- stan_glm(flipper_length_mm ~ bill_length_mm, data = penguins_bayes, family = gaussian(), prior_intercept = prior_intercept, prior = prior, prior_aux = prior_auxiliary)

# Extract the posterior samples
posterior_samples <- as.data.frame(posterior_model)

```
```{r}
summary(posterior_model)
```

b)
```{r}
library(ggplot2)
library(rstan)
library(rstanarm)
# Plot the scatterplot
plot(penguins_bayes$bill_length_mm, penguins_bayes$flipper_length_mm, xlab = "Bill Length (mm)", ylab = "Flipper Length (mm)")

# Select a subset of posterior samples (e.g., every 10th sample)
selected_samples <- posterior_samples[seq(1, nrow(posterior_samples), 100), ]

# Loop through the selected samples
for (i in 1:nrow(selected_samples)) {
  # Simulate the posterior model line
  simulated_line <- selected_samples$`(Intercept)`[i] + selected_samples$bill_length_mm[i] * penguins_bayes$bill_length_mm
  
  # Plot the line
  lines(penguins_bayes$bill_length_mm, simulated_line, col = "gray", lwd = 0.5)
}
```

The lines represent different possible model predictions based on the posterior samples of the model parameters. If the lines are close together, it suggests that there is significant uncertainty or variability in the estimated parameters. This could be due to a lack of strong evidence in the data or inherent variability in the relationship between the variables.

c)
```{r}
library(broom.mixed) # Tidy summary of the posterior model 
summary_output <- tidy(posterior_model, conf.int = TRUE, conf.level = 0.9) 
print(summary_output)

```

d)
The credible interval represents the range of plausible values for the coefficient β1. In this case, we can be 90% confident that the true value of the bill_length_mm coefficient falls within the interval from approximately 1.52064 to 1.856442.

e)
Based on these results, we can conclude that there is ample posterior evidence to suggest that penguins with longer bills tend to have longer flippers. The positive coefficient estimate and the fact that the credible interval does not include zero further support this conclusion.



6. Exercise 9.19

a)
```{r}
# Load required libraries
library(tidyverse)
library(rstan)

# Specify the observed bill length
observed_bill_length <- 51

# Specify the prior distribution parameters for flipper length
prior_mean <- 200
prior_sd <- 10

# Update the prior distribution with the observed data
observed_flipper_length <- penguins_bayes$flipper_length_mm
observed_flipper_length <- na.omit(observed_flipper_length)
posterior_mean <- (prior_mean * (prior_sd^2) + sum(observed_flipper_length)) / (prior_sd^2 + length(observed_flipper_length))
posterior_sd <- sqrt(1 / (1/prior_sd^2 + length(observed_flipper_length)/prior_sd^2))

# Simulate the posterior model for the typical flipper length with a 51 mm bill
simulated_typical_flipper_length <- rnorm(1000, posterior_mean, posterior_sd)

# Simulate the posterior predictive model for Pablo's flipper length
pablo_bill_length <- 51
pablo_posterior_mean <- (prior_mean * (prior_sd^2) + observed_flipper_length) / (prior_sd^2 + 1)
pablo_posterior_sd <- sqrt(1 / (1/prior_sd^2 + 1))
simulated_pablo_flipper_length <- rnorm(1000, pablo_posterior_mean, pablo_posterior_sd)

# Summary statistics for the simulated flipper lengths
class(simulated_typical_flipper_length)
summary(simulated_typical_flipper_length)
```

```{r}
summary(simulated_pablo_flipper_length)
```

b)
```{r}
# Density plot for the typical flipper length
simulated_typical_flipper_length <- na.omit(simulated_typical_flipper_length)
ggplot() +
  geom_density(aes(simulated_typical_flipper_length), fill = "blue", alpha = 0.5) +
  labs(title = "Posterior Model for Typical Flipper Length",
       x = "Flipper Length (mm)",
       y = "Density")


# Density plot for the posterior predictive model for Pablo's flipper length
ggplot() +
  geom_density(aes(simulated_pablo_flipper_length), fill = "green", alpha = 0.5) +
  labs(title = "Posterior Predictive Model for Pablo's Flipper Length",
       x = "Flipper Length (mm)",
       y = "Density")

# Comparing the two density plots
ggplot() +
  geom_density(aes(simulated_typical_flipper_length), fill = "blue", alpha = 0.5) +
  geom_density(aes(simulated_pablo_flipper_length), fill = "green", alpha = 0.5) +
  labs(title = "Comparison of Density Plots",
       x = "Flipper Length (mm)",
       y = "Density") +
  scale_fill_manual(values = c("blue", "green"),
                    labels = c("Typical Flipper Length", "Pablo's Flipper Length"))
```

The density plot for typical flipper length has a higher mean and a higher density at the mean. However the density for Pablo's flipper length has a much wider range of values. Both follow a normal distribution.

c)
```{r}
# Calculate the 10th and 90th quantiles
quantiles <- quantile(simulated_pablo_flipper_length, probs = c(0.1, 0.9))

# Calculate the 80% posterior prediction interval
prediction_interval <- quantiles[2] - quantiles[1]

# Interpretation of the 80% posterior prediction interval
interpretation <- "We are 80% confident that Pablo's flipper length falls within the range of ["
interpretation <- paste0(interpretation, round(quantiles[1], 2), "mm, ", round(quantiles[2], 2), "mm].")

interpretation
```

d)
The 80% credible interval for the typical flipper length among all penguins with a 51 mm bill would be narrower compared to the 80%
 posterior prediction interval for Pablo's flipper length. This is because the posterior prediction interval takes into account the uncertainty in predicting an individual's flipper length based on the observed bill length, while the credible interval for the typical flipper length considers the uncertainty in estimating the population parameter.
 
e)
```{r}
# Load required libraries
library(brms)

# Fit the Bayesian regression model
model_fit <- brm(flipper_length_mm ~ bill_length_mm,
                 data = penguins_bayes,
                 family = gaussian())

# Generate posterior predictions using posterior_predict()
post_pred <- posterior_predict(model_fit)


# Density plot from posterior predictive distribution
density_post_pred <- density(post_pred)
plot(density_post_pred, main = "Density Plot (Posterior Predictive)")

```



7. Exercise 11.10

a)
```{r}
# Create a scatter plot of body_mass_g against flipper_length_mm
ggplot(penguins_bayes, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +
  geom_point() +
  labs(x = "Flipper Length (mm)", y = "Body Mass (g)", title = "Penguin Body Mass vs Flipper Length") +
  theme_minimal()

# Summarize the relationships among the variables
summary(penguins_bayes[c("body_mass_g", "flipper_length_mm", "species")])
```


b)
```{r}

model <- stan_glm(body_mass_g ~ flipper_length_mm + species, data = penguins_bayes, chains = 4, iter = 10000) 

```

c)
```{r}
prior_summary(model)
```


```{r}
# Load required libraries
library(rstan)

summary(model)


```

d)
```{r}
tidy_summary <- tidy(model)
print(tidy_summary)
```

```{r}
library(broom.mixed) 
summary_output <- tidy(model, conf.int = TRUE, conf.level = 0.9) 
print(summary_output)
```

For the coefficient of the predictor variable "bill_length_mm," the posterior median value is approximately 1.691196, with a standard error of 0.1065277. This indicates that for every one-unit increase in the bill length of penguins, the model predicts an average increase of approximately 1.69 units in the flipper length. The credible interval for this coefficient, with a 90% confidence level, ranges from approximately 1.52064 to 1.856442. This suggests that there is strong evidence to support the conclusion that penguins with longer bills tend to have longer flippers, as the credible interval does not include zero.
In summary, the non-intercept coefficient for "bill_length_mm" provides evidence of a positive and statistically significant relationship between bill length and flipper length in penguins, as indicated by the posterior median value and the credible interval.

e)
```{r}
newdata <- data.frame(flipper_length_mm = 197, species = "Adelie")
newdata$species <- as.numeric(newdata$species)

# Simulate the posterior predictive model for the body mass of an Adelie penguin with a flipper length of 197
posterior_predict <- posterior_predict(model_fit, newdata = newdata)


model_fit <- brm(flipper_length_mm ~ species, data = penguins_bayes, family = gaussian())

# Use the corrected new data in the posterior_predict() function
posterior_predict <- posterior_predict(model_fit, newdata = penguins_bayes)

# Plot the posterior predictive distribution
hist(posterior_predict, main = "Posterior Predictive Model for Adelie Penguin Body Mass", xlab = "Body Mass (g)", col = "lightblue", border = "black")

# Describe the range and central tendency of the predicted body masses
summary(posterior_predict)
```

8. Exercise 12.5

a)
```{r}
data("bald_eagles")
head(bald_eagles)
```
```{r}
summary(bald_eagles)
```

```{r}
ggplot(bald_eagles, aes(x=count)) +
  geom_histogram(binwidth = 1, fill='blue', alpha=0.5, color='black') +
  theme_minimal() +
  labs(x="Number of Eagle Sightings", y="Frequency", title="Distribution of Eagle Sightings")
```

The most frequency occurs from 0 to 3 bald eagle sightings. This means it is rare to see a bald eagle.

b)
```{r}
ggplot(bald_eagles, aes(x=year, y=count)) +
  geom_point() +
  theme_minimal() +
  labs(x="Year", y="Number of Eagle Sightings", title="Eagle Sightings Over the Years")
```

It seems as though the number of bald eagle sightings have increased over the years.

c)
```{r}
ggplot(bald_eagles, aes(x=year, y=count, color=hours)) +
  geom_point() +
  scale_color_gradient(low = "blue", high = "red") +
  theme_minimal() +
  labs(x="Year", y="Number of Eagle Sightings", color="Observation Length (hours)", title="Eagle Sightings Over the Years")
```

It seems as though the reason there were more bald eagle sightings over the years was because the observation periods became longer.


9. Exercise 12.6

a)
```{r}
library(brms)

# Define the priors
priors <- c(prior(normal(0,10), class = "b"),
            prior(normal(0,10), class = "Intercept"),
            prior(cauchy(0,10), class = "sigma"))

# Fit the model
model <- brm(count ~ year + hours, data = bald_eagles, family = gaussian(), prior = priors)

```

```{r}
prior_summary(model)
```

The prior_summary() output suggests that your model uses non-informative priors for the regression coefficients of hours and year, a weakly informative Student's t prior for the intercept, and another weakly informative Student's prior for the residual standard deviation (sigma). This aligns with the idea of using weakly informative priors to balance prior uncertainty with the data.

b) 
The complete Bayesian structure of the Normal regression model of Y by X1 and X2
can be written as follows: 
-Likelihood: Yi∼Normal(μi,σ), where μi=β0+β1X1i+β2X2i for each observation i
-Priors: β0∼Normal(0,10),
β1∼Normal(0,10),
β2∼Normal(0,10).
σ∼HalfNormal(0,10)

c)
```{r}
pp_check(model)
```

The simulated data and the observed data seem to have some noticeable differences. This indicated our model might not be th best choice.

10. Exercise 12.7

a)
In the bald eagle analysis, a Poisson regression approach might be more appropriate than a Normal regression approach because the response variable Y represents the count of bald eagle nests, which is a discrete and non-negative variable. The Poisson distribution is commonly used to model count data, as it describes the probability of a certain number of events occurring in a fixed interval of time or space. In contrast, a Normal regression approach assumes that the response variable follows a continuous and symmetric distribution, which may not be suitable for count data.

b)
```{r}
model_poisson <- brm(count ~ year + hours, data = bald_eagles, family = poisson())

# Check the prior summary
prior_summary(model_poisson)
```

c)
The complete Bayesian structure of the Poisson regression model of Y by X1 and X2 can be written as:
Yi∼Poisson(λi)
log⁡(λi)	 =β0+β1X1i+β2X2i
βj∼Normal(0,σj),j=0,1,2	
σj∼HalfCauchy(0,10),j=0,1,2 

where 
Yi is the count of bald eagle nests for observation i
i,
λi is the expected count of nests for observation i
i,
βj is the regression coefficient for predictor Xj
Xj, and 
σj is the standard deviation of the prior distribution for βj
βj

d)
```{r}
pp_check(model_poisson)
```

The simulated data closely resembles the observed data, it suggests that the model is a good fit. 

