---
title: "STAT385 Homework 7"
output:
  html_document:
    df_print: paged
---



```{r}
library(bayesrules)
library(dplyr)
data("coffee_ratings")
coffee_ratings <- coffee_ratings %>% 
  select(farm_name, total_cup_points, aroma, aftertaste)
```

Exersise 10.13:

a)
```{r}
head(coffee_ratings)
print(coffee_ratings)
```

Using the coffee_ratings data to model ratings (total_cup_points) by aroma or aftertaste likely violates the independence assumption of the Bayesian linear regression model because the data consists of ratings and features of different batches of beans grown on different farms. The independence assumption assumes that the observations are independent of each other. However, in this case, the batches of beans from the same farm are likely to be correlated due to factors such as farming practices, soil conditions, and other farm-specific characteristics. Consequently, the observations are not independent, violating the assumption of independence required for the Bayesian linear regression model.

b)
```{r}
set.seed(84735)
new_coffee <- coffee_ratings %>% 
  group_by(farm_name) %>% 
  sample_n(1) %>% 
  ungroup()
dim(new_coffee)
```

Exercise 10.14:

a)
```{r}
library(ggplot2)

# Scatter plot
ggplot(new_coffee, aes(x = aroma, y = total_cup_points)) +
  geom_point() +
  labs(x = "Aroma Grade", y = "Total Cup Points") +
  ggtitle("Relationship between Coffee Rating and Aroma Grade")
```

The aroma grade is represented on the x-axis, while the total_cup_points rating is represented on the y-axis. Each point on the plot represents a coffee observation. Observations with higher aroma grades tend to have higher total cup points, indicating a positive relationship between aroma grade and coffee rating.

b)
```{r}
library(rstanarm)

# Define the model formula
formula <- total_cup_points ~ aroma

# Run the Bayesian Normal regression model
model <- stan_glm(formula, data = new_coffee, family = gaussian())
```

c)
```{r}
plot(model, pars = "aroma")
```

```{r}
summary(model, pars = "aroma")
```

d)
```{r}
posterior_samples <- as.matrix(model)

# Calculate the posterior median of beta1
median_beta1 <- median(posterior_samples[, "aroma"])

# Print the posterior median
print(median_beta1)
```

The posterior median of 6.15 for the aroma coefficient (β1) suggests that, on average, a one-unit increase in the aroma variable is associated with a 6.15-unit increase in the total cup points, assuming all other variables are held constant.
It's important to note that the interpretation of the aroma coefficient depends on the context of your analysis. Without further information about the specific variables and their units, it is challenging to provide a more detailed interpretation.

e)
```{r}
summary_model <- summary(model)

# Print the summary
print(summary_model)
```

Based on the provided summary output, the Bayesian Normal regression model suggests that there is evidence of a significant relationship between the aroma variable and the total cup points rating. Here's the interpretation based on the summary output:
The estimate for the aroma coefficient (β1) is 6.2, which represents the posterior median we discussed earlier. This suggests that, on average, a one-unit increase in the aroma variable is associated with a 6.2-unit increase in the total cup points rating, assuming all other variables are held constant.
The credible interval for the aroma coefficient (aroma) does not include zero. The 90% credible interval ranges from 5.8 to 6.5, indicating that there is evidence of a non-zero effect of the aroma variable on the total cup points rating.
The standard deviation (sd) associated with the aroma coefficient is 0.3, which provides information about the uncertainty or variability in the estimation of the coefficient.
The mean posterior predictive distribution (mean_PPD) of the outcome variable is 82.1, which represents the estimated average value of the total cup points rating based on the model.
The MCMC diagnostics indicate that the model has converged (Rhat=1) and the effective sample size (n_eff) for the aroma coefficient is 3465. This suggests that there is sufficient posterior information available to estimate the effect of the aroma variable on the total cup points rating.
Based on these findings, there is significant posterior evidence to suggest that the better a coffee bean's aroma, the higher its rating tends to be.

Exercise 10.15

a)
```{r}
posterior_samples <- as.matrix(model)

# Get the first set of posterior plausible parameter sets
parameter_set <- posterior_samples[1, ]

# Simulate a sample of new coffee ratings
simulated_ratings <- rnorm(572, mean = parameter_set["(Intercept)"] + parameter_set["aroma"] * new_coffee$aroma, sd = parameter_set["sigma"])
```

b)
```{r}
simulated_density <- density(simulated_ratings)

# Density plot of observed total_cup_points data
observed_density <- density(new_coffee$total_cup_points)

# Find the maximum density value
max_density <- max(max(simulated_density$y), max(observed_density$y))

# Plotting the densities with adjusted ylim
plot(simulated_density, xlim = c(0, 100), ylim = c(0, max_density*1.1), main = "Density Plot of Simulated vs. Observed Coffee Ratings")
lines(observed_density, col = "red")
legend("topright", legend = c("Simulated Ratings", "Observed Ratings"), col = c("black", "red"), lty = 1, bty = "n", cex = 0.8, inset = 0.02)

```

The density of the observed ratings is higher at median

c)
```{r}
pp_check(model)
```


d)
```{r}
model <- lm(total_cup_points ~ aroma , data = new_coffee)
residuals <- resid(model)
shapiro.test(residuals)
```

Assumption 2 assumes that the residuals follow a Normal distribution. By comparing the density plot of the simulated sample with the observed total_cup_points data, if the shapes of the two densities are similar, it suggests that the assumption of Normality for the residuals is reasonable. However, if the densities differ significantly, it may indicate violations of the Normality assumption.
The p-value obtained (less than 2.2e-16) suggests strong evidence against the null hypothesis of normality. This means that the assumption of normality for the residuals may be violated in your data. It is important to note that the Shapiro-Wilk test is sensitive to sample size, so even small deviations from normality can result in a significant p-value.


```{r}
model <- lm(total_cup_points ~ aroma , data = new_coffee)
residuals <- resid(model)

# Plotting residuals against predicted values
plot(predict(model), residuals, xlab = "Predicted Values", ylab = "Residuals", main = "Residual Plot for Assumption 3")
abline(h = 0, col = "red")
```

Assumption 3 assumes that the residuals have constant variance (σ). In the density plot, if the widths of the densities are similar across the range of total_cup_points, it suggests that the assumption of constant variance is reasonable. However, if the widths vary noticeably, it may indicate heteroscedasticity and a violation of the constant variance assumption.

Assumption 3 is not violated. The residuals are similar all throughout, meaning their is constant variance.


Exercise 10.16



a)
```{r}
library(brms)



# Define your Bayesian regression model using brms syntax
model <- brm(total_cup_points ~ aroma, data = new_coffee)

# Configure sampling parameters
sampling_params <- list(warmup = 20000, iter = 40000, chains = 4)

# Fit the model with the specified sampling parameters
fit <- brm(formula = total_cup_points ~ aroma, data = new_coffee, 
           control = list(adapt_delta = 0.95), sample_prior = "yes",
           warmup = 20000, iter = 40000, chains = 4)

```

b)
```{r}
# Assuming 'fit' is the fitted brms model

# Generate posterior predictive samples
posterior_samples <- posterior_samples(fit)

# Generate predicted ratings for the batch of beans
predicted_ratings <- posterior_predict(fit, newdata = data.frame(aroma = 84))

# Calculate raw error
raw_error <- predicted_ratings - 84
average_raw_error <- mean(raw_error)

# Calculate standardized error
standardized_error <- raw_error / sd(predicted_ratings)
average_standardized_error <- mean(standardized_error)

# Interpretation
cat("Average raw error:", average_raw_error, "\n")
cat("Average standardized error:", average_standardized_error, "\n")
```
Based on the calculations, the average raw error for the batch of beans is 469.1757. This means that, on average, the predicted ratings for the batch deviate from the actual rating of 84 by approximately 469.1757 units.
The average standardized error is 23.38164. This value represents the average difference between the predicted ratings and the actual rating, normalized by the standard deviation of the predicted ratings. The standardized error allows for comparison across different scales and provides a measure of how many standard deviations the predicted ratings deviate from the actual rating.
In summary, the average raw error indicates the average difference between the predicted and actual ratings, while the average standardized error provides a standardized measure of the deviation. Both measures can be used to assess the accuracy and precision of the model's predictions for the batch of beans.

c)
```{r}
library(bayesplot)
# Generate posterior predictive samples
posterior_samples <- as_draws_array(fit)

# Generate predicted ratings for all batches in new_coffee
predictions <- posterior_predict(fit, newdata = new_coffee)

ppc_intervals(new_coffee$total_cup_points, yrep = predictions, x = new_coffee$aroma)
```


The predictions are very similar to the observed data.
d)
```{r}
# Calculate 50% posterior prediction interval bounds
lower_bound <- apply(predictions, 1, function(x) quantile(x, probs = 0.25))
upper_bound <- apply(predictions, 1, function(x) quantile(x, probs = 0.75))

# Count the number of batches within the 50% posterior prediction interval
count_within_interval <- sum(new_coffee$total_cup_point >= lower_bound & new_coffee$total_cup_points <= upper_bound)

count_within_interval
```

Exercise 10.19:

a)
```{r}
library(rstan)

# Define the Stan model
stan_code <- "
data {
  int<lower=0> N;
  vector[N] total_cup_points;
  vector[N] aftertaste;
}

parameters {
  real intercept;
  real slope;
  real<lower=0> sigma;
}

model {
  total_cup_points ~ normal(intercept + slope * aftertaste, sigma);
}

generated quantities {
  vector[N] y_rep;
  for (i in 1:N) {
    y_rep[i] = normal_rng(intercept + slope * aftertaste[i], sigma);
  }
}
"

# Prepare the data
data <- list(
  N = nrow(new_coffee),
  total_cup_points = new_coffee$total_cup_points,
  aftertaste = new_coffee$aftertaste
)

# Set the Stan model options
stan_options <- list(
  warmup = 20000,
  iter = 40000,
  chains = 4,
  cores = parallel::detectCores()
)

# Run Stan
fit <- stan_glm(total_cup_points ~ aftertaste, data = new_coffee, family = gaussian(), 
                prior = normal(0, 10), chains = stan_options$chains, 
                iter = stan_options$iter, warmup = stan_options$warmup,
                cores = stan_options$cores)

# Extract posterior samples
posterior_samples <- posterior_samples(fit)

# Extract simulated values
simulated_values <- as.data.frame(fit$sim)
```

b)
```{r}
# Plot observed vs. predicted values
plot(new_coffee$total_cup_points, fitted(fit), xlab = "Observed total_cup_points", ylab = "Predicted total_cup_points", main = "Residual Plot")
abline(0, 1, col = "red")  # Add a reference line

# Add residuals to the plot
residuals <- new_coffee$total_cup_points - fitted(fit)
points(fitted(fit), residuals, col = "blue", pch = 16)
```

d) If I could only pick one predictor, I would choose aftertaste because it seems to be the slightly more indicative of total cup points and has a clear positive correlation, although aroma is still a decent predictor as well.